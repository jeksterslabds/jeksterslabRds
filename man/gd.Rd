% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gd.R
\name{gd}
\alias{gd}
\title{Gradient Descent.}
\usage{
gd(X, y, aFUN, eta, epochs, criteria = 1e-08, final = TRUE, ...)
}
\arguments{
\item{X}{The data matrix,
that is an \eqn{n \times k} matrix of \eqn{n} observations
of \eqn{k} regressors,
which includes a regressor whose value is 1 for each observation.}

\item{y}{\eqn{n \times 1} vector of observations on the dependent variable.}

\item{aFUN}{Activation function.}

\item{eta}{\eqn{\eta} learning rate.}

\item{epochs}{Number of iterations.}

\item{criteria}{Stopping criteria.
The algorithm stops
if the sum of the absolute values of delta is less than \code{criteria}.}

\item{final}{Logical.
If \code{TRUE}, returns the value of \code{w} for the final iteration.
If \code{FALSE}, returns all values of \code{w}
from the random start to the final iteration.}

\item{...}{Arguments to pass to \code{aFUN}.}
}
\value{
If \code{final} is \code{TRUE},
returns a vector of \eqn{k} estimated weights \code{w} for the final iteration.
If \code{final} is \code{FALSE},
returns all the values of \code{w}
from the random start to the final iteration.
}
\description{
Implements the gradient descent algorithm.
Weights are updated using the following equation
\eqn{\mathbf{w} \rightarrow \mathbf{w} \eta \Delta}
where \eqn{\Delta = f(\mathbf{Xw}) - \mathbf{y}} and
\eqn{f} is the activation function.
}
\keyword{gd}
